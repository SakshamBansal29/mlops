1. Create a github repot and clone it
2. add src and experiments folder
3. add data, models, reports to itignore
4 Add git commit push

Setting up dvc pipeline (without params)
5 create dvc.yaml file and add stages to it.
6 dvc init then do dvc repro to test the pipeline automation (check dvc dag)
7 git add, commit, push

Setting up the DVC pipeline (with params)
8 add params.yaml file
9 add params setup 
10 do "dvc repro" again to test the pipeline along with the params
11  Git add commit push

Experiments with DVC
12 pip install dvclive
13 Add dvc livecode block
14 do "dvc exp run", will create a new dvc.yaml file(if not there) and dvclive directory (each run will be considered as an experiment by DVC)
15 do "dvc exp show" on terminal to see the experiments or use extensions on VS code
16 do "dvc exp remove {exp-name} to remove exp (optional) | "dvc exp apply {exp-name}" to reproduce prev exp
17 change params re-run code (produce new experiments)
18 now git add commit push

Adding remote s3 storage to DVC:
19 login to AWS 
20 Create an IAM User
21 Create S3 Bucket
22 pip install dvc[s3]
23 pip install awscli
24 "aws configure" in terminal
25 dvc remote add -d dvcstore s3://bucketname
26 dvc commit, push the exp putcome that you want to keep
27 git add commit push